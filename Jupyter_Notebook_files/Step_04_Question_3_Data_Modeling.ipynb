{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T15:56:44.950477Z",
     "start_time": "2019-09-25T15:56:41.219762Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sklearn import datasets, metrics, svm, linear_model\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression, LogisticRegressionCV, RidgeCV, LassoCV, PassiveAggressiveClassifier, Perceptron, RidgeClassifier, SGDClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "import scipy.stats as stats\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm_notebook\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "import textacy\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:09:43.934935Z",
     "start_time": "2019-09-25T12:09:43.925990Z"
    }
   },
   "outputs": [],
   "source": [
    "########### READ ###########\n",
    "# https://stackoverflow.com/questions/46507606/what-does-the-cv-stand-for-in-sklearn-linear-model-logisticregressioncv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:09:44.065782Z",
     "start_time": "2019-09-25T12:09:43.937203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decided to use .sample - the original dataset is large and takes long time to run models\n",
    "restaurants = pd.read_pickle('/Users/mai/Desktop/yelp_dataset/to_submit/restaurants_clean.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:09:44.494243Z",
     "start_time": "2019-09-25T12:09:44.068463Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_pickle('/Users/mai/Desktop/yelp_dataset/to_submit/review_sentimentanalysis.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datasets per business status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:09:44.590063Z",
     "start_time": "2019-09-25T12:09:44.496299Z"
    }
   },
   "outputs": [],
   "source": [
    "successful_reviews = reviews[reviews.prediction_col == 1]\n",
    "failed_reviews = reviews[reviews.prediction_col == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:09:44.595353Z",
     "start_time": "2019-09-25T12:09:44.591657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66514, 16)\n",
      "(67770, 16)\n"
     ]
    }
   ],
   "source": [
    "print(successful_reviews.shape)\n",
    "print(failed_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add more words to the stop_word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:09:44.603450Z",
     "start_time": "2019-09-25T12:09:44.597168Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:09:44.612532Z",
     "start_time": "2019-09-25T12:09:44.607976Z"
    }
   },
   "outputs": [],
   "source": [
    "words_to_remove = [\n",
    "                    'com biz_photos mudalytuatnzm2k9zoh27q select', \n",
    "                    'com biz_photos mudalytuatnzm2k9zoh27q select', \n",
    "                    'don know', 'don think', 'don think ll going', 'don want', 'http',\n",
    "                    'biz_photos', 'http www youtube com watch', \n",
    "                    'let just say', 'love love', 'new york', 'www yelp com',  \n",
    "                    '6_jqe5olfhoz1t_m96g85g', 'dyuoxkw4dtljsthdxdxslg', 'mudalytuatnzm2k9zoh27q', \n",
    "                    'yelp com biz_photos', \n",
    "                    'yelp com biz_photos dyuoxkw4dtljsthdxdxslg select', \n",
    "                    'yelp com biz_photos mudalytuatnzm2k9zoh27q', \n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:09:44.620293Z",
     "start_time": "2019-09-25T12:09:44.617306Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words_list.extend(words_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T13:56:49.641239Z",
     "start_time": "2019-09-24T13:56:49.634039Z"
    }
   },
   "source": [
    "# Create a function to extract frequently used keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:09:44.629840Z",
     "start_time": "2019-09-25T12:09:44.625900Z"
    }
   },
   "outputs": [],
   "source": [
    "def frequency_analyzer(data, start, end):\n",
    "    cvec = CountVectorizer(stop_words=stop_words_list, ngram_range=(start, end))\n",
    "\n",
    "    # Fit our vectorizer using our train data\n",
    "    cvec.fit(data)\n",
    "\n",
    "    # Transform training data\n",
    "    cvec_mat = cvec.transform(data)\n",
    "\n",
    "    # Words occuring\n",
    "    words = cvec.get_feature_names()\n",
    "    length = len(cvec.get_feature_names())\n",
    "\n",
    "    # Create a ranking table\n",
    "    \n",
    "    a = cvec_mat.sum(axis=0)\n",
    "    rank = pd.DataFrame(a, columns=words).transpose().sort_values(by=0, ascending=False)\n",
    "    rank.reset_index(inplace=True)\n",
    "\n",
    "    return rank[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success restaurants with positive sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:09:44.646030Z",
     "start_time": "2019-09-25T12:09:44.631918Z"
    }
   },
   "outputs": [],
   "source": [
    "success_positive_reviews = successful_reviews[successful_reviews['vader_result'] == 'positive']\n",
    "Xsp = success_positive_reviews['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:12:07.486560Z",
     "start_time": "2019-09-25T12:09:44.647917Z"
    }
   },
   "outputs": [],
   "source": [
    "Xsp1 = frequency_analyzer(Xsp, 1, 1)\n",
    "Xsp2 = frequency_analyzer(Xsp, 2, 2)\n",
    "Xsp3 = frequency_analyzer(Xsp, 3, 3)\n",
    "Xsp4 = frequency_analyzer(Xsp, 4, 4)\n",
    "Xsp5 = frequency_analyzer(Xsp, 5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success restaurants with negative sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:12:07.513600Z",
     "start_time": "2019-09-25T12:12:07.489199Z"
    }
   },
   "outputs": [],
   "source": [
    "successful_negative_reviews = successful_reviews[successful_reviews['vader_result'] == 'negative']\n",
    "Xsn = successful_negative_reviews['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:12:26.849340Z",
     "start_time": "2019-09-25T12:12:07.515138Z"
    }
   },
   "outputs": [],
   "source": [
    "Xsn1 = frequency_analyzer(Xsn, 1, 1)\n",
    "Xsn2 = frequency_analyzer(Xsn, 2, 2)\n",
    "Xsn3 = frequency_analyzer(Xsn, 3, 3)\n",
    "Xsn4 = frequency_analyzer(Xsn, 4, 4)\n",
    "Xsn5 = frequency_analyzer(Xsn, 5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failed restaurants with positive sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:12:26.880116Z",
     "start_time": "2019-09-25T12:12:26.850971Z"
    }
   },
   "outputs": [],
   "source": [
    "failed_positive_reviews = failed_reviews[failed_reviews['vader_result'] == 'positive']\n",
    "Xfp = failed_positive_reviews['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:15:13.221484Z",
     "start_time": "2019-09-25T12:12:26.882049Z"
    }
   },
   "outputs": [],
   "source": [
    "Xfp1 = frequency_analyzer(Xfp, 1, 1)\n",
    "Xfp2 = frequency_analyzer(Xsn, 2, 2)\n",
    "Xfp3 = frequency_analyzer(Xfp, 3, 3)\n",
    "Xfp4 = frequency_analyzer(Xfp, 4, 4)\n",
    "Xfp5 = frequency_analyzer(Xfp, 5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failed restaurants with negative sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:15:13.240443Z",
     "start_time": "2019-09-25T12:15:13.223940Z"
    }
   },
   "outputs": [],
   "source": [
    "failed_negative_reviews = failed_reviews[failed_reviews['vader_result'] == 'negative']\n",
    "Xfn = failed_negative_reviews['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:15:53.508481Z",
     "start_time": "2019-09-25T12:15:13.242719Z"
    }
   },
   "outputs": [],
   "source": [
    "Xfn1 = frequency_analyzer(Xfn, 1, 1)\n",
    "Xfn2 = frequency_analyzer(Xfn, 2, 2)\n",
    "Xfn3 = frequency_analyzer(Xfn, 3, 3)\n",
    "Xfn4 = frequency_analyzer(Xfn, 4, 4)\n",
    "Xfn5 = frequency_analyzer(Xfn, 5, 5)\n",
    "Xfn6 = frequency_analyzer(Xfn, 6, 6)\n",
    "Xfn7 = frequency_analyzer(Xfn, 7, 7)\n",
    "Xfn8 = frequency_analyzer(Xfn, 8, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataframe per review type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T14:14:16.551122Z",
     "start_time": "2019-09-24T14:14:16.541823Z"
    }
   },
   "source": [
    "## Change column names for all DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:15:53.517241Z",
     "start_time": "2019-09-25T12:15:53.510492Z"
    }
   },
   "outputs": [],
   "source": [
    "df_list = [Xsp1, Xsp2, Xsp3, Xsp4, Xsp5, \\\n",
    "           Xsn1, Xsn2, Xsn3, Xsn4, Xsn5, \\\n",
    "           Xfp1, Xfp2, Xfp3, Xfp4, Xfp5, \\\n",
    "           Xfn1, Xfn2, Xfn3, Xfn4, Xfn5, Xfn6, Xfn7, Xfn8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:15:53.526542Z",
     "start_time": "2019-09-25T12:15:53.522235Z"
    }
   },
   "outputs": [],
   "source": [
    "successful_positive_df_list = [Xsp1, Xsp2, Xsp3, Xsp4, Xsp5]\n",
    "successful_negative_df_list = [Xsn1, Xsn2, Xsn3, Xsn4, Xsn5]\n",
    "failed_positive_df_list = [Xfp1, Xfp2, Xfp3, Xfp4, Xfp5]\n",
    "failed_negative_df_list = [Xfn1, Xfn2, Xfn3, Xfn4, Xfn5, Xfn6, Xfn7, Xfn8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:15:53.543626Z",
     "start_time": "2019-09-25T12:15:53.529516Z"
    }
   },
   "outputs": [],
   "source": [
    "for d in df_list:\n",
    "    data = d\n",
    "    row_n = 0\n",
    "    word_sample = data['index'][row_n]\n",
    "    i = len(word_sample.split(' '))\n",
    "    data.columns = ['ngram_'+str(i), 'ngram_'+str(i)+'_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T12:15:53.575122Z",
     "start_time": "2019-09-25T12:15:53.551845Z"
    }
   },
   "outputs": [],
   "source": [
    "success_positive_result = pd.concat([Xsp1, Xsp2, Xsp3, Xsp4, Xsp5], axis=1, sort=False)\n",
    "success_negative_result = pd.concat([Xsn1, Xsn2, Xsn3, Xsn4, Xsn5], axis=1, sort=False)\n",
    "failed_positive_result = pd.concat([Xfp1, Xfp2, Xfp3, Xfp4, Xfp5], axis=1, sort=False)\n",
    "failed_negative_result = pd.concat([Xfn1, Xfn2, Xfn3, Xfn4, Xfn5, Xfn6, Xfn7, Xfn8], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T13:21:41.818296Z",
     "start_time": "2019-09-25T13:21:41.796219Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_1</th>\n",
       "      <th>ngram_1_count</th>\n",
       "      <th>ngram_2</th>\n",
       "      <th>ngram_2_count</th>\n",
       "      <th>ngram_3</th>\n",
       "      <th>ngram_3_count</th>\n",
       "      <th>ngram_4</th>\n",
       "      <th>ngram_4_count</th>\n",
       "      <th>ngram_5</th>\n",
       "      <th>ngram_5_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food</td>\n",
       "      <td>39917</td>\n",
       "      <td>go back</td>\n",
       "      <td>2495</td>\n",
       "      <td>definitely come back</td>\n",
       "      <td>456</td>\n",
       "      <td>would definitely come back</td>\n",
       "      <td>190</td>\n",
       "      <td>would definitely come back try</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>36318</td>\n",
       "      <td>first time</td>\n",
       "      <td>2483</td>\n",
       "      <td>food great service</td>\n",
       "      <td>353</td>\n",
       "      <td>great food great service</td>\n",
       "      <td>123</td>\n",
       "      <td>buy one get one free</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>place</td>\n",
       "      <td>32120</td>\n",
       "      <td>really good</td>\n",
       "      <td>2474</td>\n",
       "      <td>wait go back</td>\n",
       "      <td>353</td>\n",
       "      <td>would definitely go back</td>\n",
       "      <td>123</td>\n",
       "      <td>definitely come back next time</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great</td>\n",
       "      <td>29004</td>\n",
       "      <td>come back</td>\n",
       "      <td>2321</td>\n",
       "      <td>definitely go back</td>\n",
       "      <td>333</td>\n",
       "      <td>great service great food</td>\n",
       "      <td>89</td>\n",
       "      <td>great food great service great</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>service</td>\n",
       "      <td>21975</td>\n",
       "      <td>food good</td>\n",
       "      <td>2140</td>\n",
       "      <td>would go back</td>\n",
       "      <td>321</td>\n",
       "      <td>would definitely recommend place</td>\n",
       "      <td>78</td>\n",
       "      <td>say enough good things place</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ngram_1  ngram_1_count      ngram_2  ngram_2_count               ngram_3  \\\n",
       "0     food          39917      go back           2495  definitely come back   \n",
       "1     good          36318   first time           2483    food great service   \n",
       "2    place          32120  really good           2474          wait go back   \n",
       "3    great          29004    come back           2321    definitely go back   \n",
       "4  service          21975    food good           2140         would go back   \n",
       "\n",
       "   ngram_3_count                           ngram_4  ngram_4_count  \\\n",
       "0            456        would definitely come back            190   \n",
       "1            353          great food great service            123   \n",
       "2            353          would definitely go back            123   \n",
       "3            333          great service great food             89   \n",
       "4            321  would definitely recommend place             78   \n",
       "\n",
       "                          ngram_5  ngram_5_count  \n",
       "0  would definitely come back try             24  \n",
       "1            buy one get one free             23  \n",
       "2  definitely come back next time             20  \n",
       "3  great food great service great             20  \n",
       "4    say enough good things place             17  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_positive_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-25T11:58:43.127Z"
    }
   },
   "outputs": [],
   "source": [
    "success_positive_result.to_csv('success_positive_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T13:21:50.720512Z",
     "start_time": "2019-09-25T13:21:50.699999Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_1</th>\n",
       "      <th>ngram_1_count</th>\n",
       "      <th>ngram_2</th>\n",
       "      <th>ngram_2_count</th>\n",
       "      <th>ngram_3</th>\n",
       "      <th>ngram_3_count</th>\n",
       "      <th>ngram_4</th>\n",
       "      <th>ngram_4_count</th>\n",
       "      <th>ngram_5</th>\n",
       "      <th>ngram_5_count</th>\n",
       "      <th>ngram_6</th>\n",
       "      <th>ngram_6_count</th>\n",
       "      <th>ngram_7</th>\n",
       "      <th>ngram_7_count</th>\n",
       "      <th>ngram_8</th>\n",
       "      <th>ngram_8_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food</td>\n",
       "      <td>7212</td>\n",
       "      <td>go back</td>\n",
       "      <td>504</td>\n",
       "      <td>never go back</td>\n",
       "      <td>154</td>\n",
       "      <td>would never go back</td>\n",
       "      <td>16</td>\n",
       "      <td>could give zero stars would</td>\n",
       "      <td>7</td>\n",
       "      <td>wife friends show anymore unless see</td>\n",
       "      <td>3</td>\n",
       "      <td>square sad exclude place list nobody deserves</td>\n",
       "      <td>3</td>\n",
       "      <td>asked complete strangers sitting next bar girl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>place</td>\n",
       "      <td>4883</td>\n",
       "      <td>customer service</td>\n",
       "      <td>448</td>\n",
       "      <td>never come back</td>\n",
       "      <td>51</td>\n",
       "      <td>really wanted like place</td>\n",
       "      <td>16</td>\n",
       "      <td>never go back recommend anyone</td>\n",
       "      <td>4</td>\n",
       "      <td>heard restaffing def needed except front</td>\n",
       "      <td>3</td>\n",
       "      <td>sure kaya woman surface management eventually ...</td>\n",
       "      <td>3</td>\n",
       "      <td>drinks atmosphere clanky noisy yard house scal...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service</td>\n",
       "      <td>3838</td>\n",
       "      <td>first time</td>\n",
       "      <td>313</td>\n",
       "      <td>worst service ever</td>\n",
       "      <td>51</td>\n",
       "      <td>worst customer service ever</td>\n",
       "      <td>14</td>\n",
       "      <td>never came back check us</td>\n",
       "      <td>4</td>\n",
       "      <td>noisy yard house scale restaurant time</td>\n",
       "      <td>3</td>\n",
       "      <td>assure go ever since last time week</td>\n",
       "      <td>3</td>\n",
       "      <td>time square sad exclude place list nobody dese...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one</td>\n",
       "      <td>3261</td>\n",
       "      <td>come back</td>\n",
       "      <td>306</td>\n",
       "      <td>would go back</td>\n",
       "      <td>49</td>\n",
       "      <td>could give stars would</td>\n",
       "      <td>12</td>\n",
       "      <td>deserves come place happy excited</td>\n",
       "      <td>3</td>\n",
       "      <td>could give place negative stars would</td>\n",
       "      <td>3</td>\n",
       "      <td>time heard restaffing def needed except front</td>\n",
       "      <td>3</td>\n",
       "      <td>believe attitude careless carefree behavior ev...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>3001</td>\n",
       "      <td>food good</td>\n",
       "      <td>293</td>\n",
       "      <td>poor customer service</td>\n",
       "      <td>44</td>\n",
       "      <td>took 30 minutes get</td>\n",
       "      <td>12</td>\n",
       "      <td>heard restaffing def needed except</td>\n",
       "      <td>3</td>\n",
       "      <td>customers point asked complete strangers sitting</td>\n",
       "      <td>3</td>\n",
       "      <td>sitting next bar girl real even wanna</td>\n",
       "      <td>3</td>\n",
       "      <td>go ever since last time week ago rudely</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ngram_1  ngram_1_count           ngram_2  ngram_2_count  \\\n",
       "0     food           7212           go back            504   \n",
       "1    place           4883  customer service            448   \n",
       "2  service           3838        first time            313   \n",
       "3      one           3261         come back            306   \n",
       "4     like           3001         food good            293   \n",
       "\n",
       "                 ngram_3  ngram_3_count                      ngram_4  \\\n",
       "0          never go back            154          would never go back   \n",
       "1        never come back             51     really wanted like place   \n",
       "2     worst service ever             51  worst customer service ever   \n",
       "3          would go back             49       could give stars would   \n",
       "4  poor customer service             44          took 30 minutes get   \n",
       "\n",
       "   ngram_4_count                             ngram_5  ngram_5_count  \\\n",
       "0             16         could give zero stars would              7   \n",
       "1             16      never go back recommend anyone              4   \n",
       "2             14            never came back check us              4   \n",
       "3             12   deserves come place happy excited              3   \n",
       "4             12  heard restaffing def needed except              3   \n",
       "\n",
       "                                            ngram_6  ngram_6_count  \\\n",
       "0              wife friends show anymore unless see              3   \n",
       "1          heard restaffing def needed except front              3   \n",
       "2            noisy yard house scale restaurant time              3   \n",
       "3             could give place negative stars would              3   \n",
       "4  customers point asked complete strangers sitting              3   \n",
       "\n",
       "                                             ngram_7  ngram_7_count  \\\n",
       "0      square sad exclude place list nobody deserves              3   \n",
       "1  sure kaya woman surface management eventually ...              3   \n",
       "2                assure go ever since last time week              3   \n",
       "3      time heard restaffing def needed except front              3   \n",
       "4              sitting next bar girl real even wanna              3   \n",
       "\n",
       "                                             ngram_8  ngram_8_count  \n",
       "0  asked complete strangers sitting next bar girl...              3  \n",
       "1  drinks atmosphere clanky noisy yard house scal...              3  \n",
       "2  time square sad exclude place list nobody dese...              3  \n",
       "3  believe attitude careless carefree behavior ev...              3  \n",
       "4            go ever since last time week ago rudely              3  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_negative_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T17:20:15.247427Z",
     "start_time": "2019-09-24T17:20:15.239173Z"
    }
   },
   "outputs": [],
   "source": [
    "failed_negative_result.to_csv('failed_negative_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
